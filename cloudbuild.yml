steps:
  # Step 1: Clone GitHub repo
  - name: 'gcr.io/cloud-builders/git'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        git clone https://github.com/chandranajith07/Airflow_for_data_load.git repo
        cd repo
        echo "Repository cloned successfully."

  # Step 2: Copy the Python file to GCS bucket
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Uploading file to GCS bucket..."
        gsutil -m cp repo/gcs_to_bigquery.py ${_BUCKET_PATH}
        echo "Upload complete."

substitutions:
  _BUCKET_PATH: gs://us-central1-composer1-472f769e-bucket/dags

options:
  logging: CLOUD_LOGGING_ONLY
